✅ Phase 1 — Fundamentals (LOCAL LLM)

Llama 3.2 → simple chat

Messages, memory, system prompt

Streaming

Parameters (temperature, top_p)

✅ Phase 2 — Tool Calling (LOCAL AGENT)

Learn Ollama tool-calling

Build a manual agent loop

Add multiple tools

Add small planning logic

✅ Phase 3 — LangChain Core

ChatOllama

Runnables (LCEL)

Tools

Retrievers

Prompt templates

✅ Phase 4 — LangChain Agents (optional shortcut)

create_react_agent

create_tool_chat_agent

Memory + tool usage

✅ Phase 5 — LangGraph (real agent framework)

Nodes

State

Edges

Tool nodes

Loops

Checkpoints

Persistence

Human-in-the-loop

✅ Phase 6 — MCP (modern agent integration)

Build MCP server

Expose tools

Expose resources

Connect MCP → LangChain

Connect MCP → LangGraph

### Future Learning

https://docs.ollama.com/modelfile